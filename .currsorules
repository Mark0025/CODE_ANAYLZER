"""
IMPORTANT: DO NOT MODIFY THIS FILE WITHOUT EXPLICIT PERMISSION
CONTACT: THE AI RE INVESTOR (405-963-2596)
LAST MODIFIED: 2024-11-27
"""

# Disable all markdown processing
disable_markdown: true

# File patterns to completely ignore
ignore:
 - IGNORE ANY FILE - YOU ARE ONLY REPORTING ON CODE READING IT AND REPORTING ON IT -
 - YOU OCCASIONALY BE ASKED TO MAKE ONE FILE CHANGE HERE AND THERE MOST TIME YOU WILL BUILD A XML - LONG DETAILED FUTRE PLAN THAT WILL BE BROKEN DOWN INTO SMALERER YAML FILES THAT WE CAN RUN AND TEST -- 
 - 
  - "*.md"
  - "*.markdown"
  - "*.MD"
  - "README*"
  - "PUBLISHING*"
  - "LICENSE*"
  - "*.toml"
  - "*.yaml"
  - "*.yml"
  - "docs/*"
  - ".github/*"

# Directory patterns to ignore
ignore_dirs:
  - ".git"
  - "__pycache__"
  - "*.egg-info"
  - "dist"
  - "build"
  - "docs"

# Language settings
python:
  enabled: true
  lint: true
  format: true
  typing:
    required: true
    strict: true
  docstrings:
    required: true
    style: "pep257"
  test:
    framework: "pytest"
    plugins:
      - "pytest-mock"
      - "pytest-cov"
      - "pytest-asyncio"
    fixtures:
      - "CaptureFixture"
      - "FixtureRequest"
      - "LogCaptureFixture"
      - "MonkeyPatch"
      - "MockerFixture"
  dependencies:
    manager: "uv"
    virtual_env: true
  style:
    formatter: "ruff"
    line_length: 88
    import_order: true
  problem_solving:
    pattern: "Think smart about errors:"
    checklist:
    order-of-thought:"""
     0 - "Will fixing one issue , library , reading previous logs, or looking at imports and looking at file structure  fix many?"
     1 - "Is there a root cause is their one behind that one behind that one behind that one ??"
     2 - "Is there a common pattern?"
     3 - "What Python libraries could help?"
"""
# Testing requirements
test_requirements:
  - location: "./tests"
  - init_files: true
  - typing: true
  - docstrings: true
  - framework: "pytest"
  - annotations: true

# CI/CD settings
ci_cd:
  provider: "github-actions"
  checks:
    - typing
    - lint
    - test
    - coverage

# AI Development settings
ai_development:
  docstring_format: "google"
  type_annotations: true
  error_handling: true
  logging: true
  modular_design: true
  configuration: "env_vars"

# Global settings
spell_check: false

# Problem solving strategy
problem_solving_strategy:
  steps:
    - identify_patterns: - YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
        description: "Look for common patterns in errors"
        question: "Is there a recurring theme in these errors?"
    
    - library_solutions: YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
        description: "Check for existing library solutions"
        question: "Is there a Python/framework library that solves this?"
    
    - root_cause: YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
        description: "Find the root cause"
        question: "Can fixing one issue solve multiple problems?"
    
    - solution_impact: YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
        description: "Evaluate solution impact"
        question: "How will this solution affect other parts of the code?"
    
    - check_hardcoded_values: YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
        description: "Always check for hardcoded values first"
        questions:
          - "Are there any hardcoded values like 'test-key'?"
          - "Is this a placeholder someone added?"
          - "Could this be overriding environment variables?"
        rules:
          - "Never use placeholder values in code"
          - "Use empty strings or None as defaults"
          - "Use comments for developer guidance"
        examples:
          bad: |
            api_key = "test-key"  # Bad: Hardcoded placeholder
          good: |
            api_key = ""  # Good: Empty default
            # Developer: Set OPENAI_API_KEY in .env file
            
    - simplest_solution_first: YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
        description: "Look for the simplest fix first"
        questions:
          - "Could this be a simple hardcoded value?"
          - "Are we overcomplicating the solution?"
          - "What's the fastest way to verify?"
        rules:
          - "Search for hardcoded values before adding complexity"
          - "Fix at source rather than adding layers"
          - "Use grep/search before creating new systems"
    - verify_tech_stack:
        description: "Check if issue is tech stack related"
        questions:
          - "Is this a UV installation issue?"
          - "Is this a FastAPI configuration problem?"
          - "Is this a database connection issue?"
          - "Is this an AI integration problem?"

# AI First Strategy
ai_first_strategy:
  principles:
    - leverage_ai_strengths:
        description: "Use AI's natural capabilities first"
        questions:
          - "Can AI handle this natively?"
          - "Are we overcomplicating what AI does well?"
          - "Are we reinventing AI functionality?"
    
    - simplify_before_building:
        description: "Remove unnecessary complexity"
        questions:
          - "Are we building something AI already does?"
          - "Can we remove layers between AI and task?"
          - "Is our code getting in AI's way?"
    
    - focus_on_integration:
        description: "Focus on connecting, not recreating"
        questions:
          - "How can we best connect to AI capabilities?"
          - "What's the minimal code needed?"
          - "Are we adding value or just layers?"

    - measure_complexity:
        description: "Evaluate solution complexity"
        metrics:
          - "Lines of our code vs AI utilization"
          - "Number of potential failure points"
          - "Maintenance burden"

# Problem Solving Workflow
problem_solving_workflow:
  steps:
    1. identify_ai_capabilities:
        question: "What can AI already do here?"
        example: "CrewAI can analyze code without our file walking"
    
    2. remove_unnecessary_code:
        question: "What code can we remove?"
        example: "Remove manual file analysis, trust CrewAI"
    
    3. enhance_ai_integration:
        question: "How can we better integrate with AI?"
        example: "Use CrewAI's native code understanding"
    
    4. validate_simplification:
        question: "Is this simpler than before?"
        metrics:
          - Code reduction
          - Fewer error cases
          - Better AI utilization

# Add to existing .currsorules

# Content modification rules
content_modification:
  rules:
    - never_remove_existing:
        enabled: true
        description: "Never remove existing content, only add new content"
        policy: "append_only"
    
    - no_placeholders:
        enabled: true
        description: "Never use placeholder values in code"
        forbidden_patterns:
          - "test-key"
          - "your-key-here"
          - "placeholder"
          - "xxx-xxx"
        alternatives:
          - "Use empty string ''"
          - "Use None"
          - "Use descriptive comments"
    
    - sensitive_data:
        enabled: true
        description: "Handle sensitive data appropriately"
        rules:
          - "Keep existing API keys and tokens as is"
          - "Do not replace with placeholders"
          - "Add warnings about security when relevant"
          - "Use .env.example for new installations only"

# Update strategy
update_strategy:
  method: "append_only"
  rules:
    - "Always add to end of sections"
    - "Never modify existing rules"
    - "Keep all historical rules"
    - "Only append new configurations"

# Add to existing .currsorules

git_strategy:
  commit_rules:
    - sensitive_data:
        description: "Handle sensitive data in commits"
        rules:
          - "Never commit .env files"
          - "Use .env.example.template for examples"
          - "Remove API keys before committing"
          - "Check git diff for sensitive data"
        error_patterns:
          - "*.env"
          - "*api_key*"
          - "*secret*"
          - "*password*"

    - commit_organization:
        description: "Organize commits logically"
        structure:
          - core_files:
              - "*.py"
              - "*.json"
              - "pyproject.toml"
          - documentation:
              - "*.md"
              - "docs/"
              - "DEV-MAN-CREW/"
          - scripts:
              - "scripts/"
              - "*.sh"
          - tests:
              - "tests/"
              - "conftest.py"

    - commit_messages:
        description: "Structure commit messages"
        template: |
          üèóÔ∏è {emoji} {short_description}

          CHANGES:
          ---------
          {detailed_changes}

          TECHNICAL DETAILS:
          -----------------
          {technical_notes}

          SECURITY:
          ---------
          - [ ] No sensitive data
          - [ ] No API keys
          - [ ] No credentials

          DOCUMENTATION:
          -------------
          - [ ] Updated relevant docs
          - [ ] Added new docs if needed

          CODED BY THE AI RE INVESTOR -- WWW.THEAIREINVESTOR.COM
          For AI Development & Consulting Services
          Call: 405-963-2596

# Add to existing .currsorules

crew_output_handling:
  rules:
    - task_output_structure:
        description: "Use CrewAI's native task output structure"
        pattern: |
          task_output = task.output
          output = {
              "description": task_output.description,
              "raw": task_output.raw,
              "json": task_output.json_dict if hasattr(task_output, 'json_dict') else None
          }
    
    - output_storage:
        description: "Maintain organized output storage"
        structure:
          base_dir: "crews/crew-output"
          crew_dirs:
            - "{crew_name}/latest_{type}.json"
            - "{crew_name}/{timestamp}_{type}.json"
          required_metadata:
            - timestamp
            - crew_name
            - analysis_type
            - version

    - timeline_documentation:
        description: "Maintain historical documentation"
        rules:
          - "Never delete old status entries"
          - "Add new entries at top with timestamp"
          - "Keep all historical context"
          - "Mark updates clearly"

# .currsorules - Code Analyzer Decision Framework

## Decision Tree for Code Changes:

### 1. üéØ Single File Quick Fixes
USE: YAML AND ANAYLZE CODE STRUCTURE AND IMPORTS ALWAYS LARGEST ISSUES FIRST - ANNALYZE SO YOU KNOW WITH 96% CONFIDIENCE YOUR FIX WILL BE A IMPROVMENT NOT CONFUSION
```mermaid
graph TD
    A[Single File Change] -->|Quick Fix| B[Use Cursor]
    A -->|Small Refactor| B[Use Cursor]
    
    Examples[Examples:]
    * Variable renaming
    * Function signature updates
    * Single import fixes
```

### 2. üèóÔ∏è Multi-File/Structural Changes
USE: **YAML Automation** YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
```mermaid
graph TD
    A[Multi-File Change] -->|Generate YAML| B[Use CODE_ANALYZER]
    A -->|Run Command| C[Auto-Updates]
    
    Examples[Examples:]
    * Import fixes across files
    * Directory restructuring
    * Pattern implementation
```

### 3. üîß System Commands
USE: **Automation Scripts**  YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
```mermaid
graph TD
    A[System Tasks] -->|Run Script| B[Automated Process]
    A -->|No Manual Steps| C[Verified Results]
    
    Examples[Examples:]
    * Directory creation
    * Test running
    * Build processes
```

## Command Categories:
YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -

    MAKE SURE FILE FOLDER AND STRUCTURE IS CORRECT IN ANAYLZE STAGE BEFORE BUILD STAGE OR YOU ARE CREATING PROBLEMS FOR YOU AND OTHERS -

### 1. YAML-Based Updates:
```bash
# For multi-file changes
python -m code_analyzer.crews.dev_crews.run_updates \
    --spec yaml_tools/TYPE/update-name.yaml \
    --verbose \
    --target ./
```

### 2. System Setup:
```bash
# For system-wide changes
python -m code_analyzer.cli.auto_setup \
    --type [setup|test|docs] \
    --verbose
```

### 3. Documentation:
```bash
# For documentation updates
python -m code_analyzer.crews.doc_crews.update \
    --target DEV-NOW/CURRENT\
    --type markdown -
    --verbose
    -- XML - LONG FORM - PLAN -FUTURE PLAUYING OUT HOW THIS IMPACTS THE CODEBASE AND CONFIDENCE SCORE THAT WHEN RAN WE WILL BE AT 96%
    --{FOLDER-NAME} - NESTED FOLDERS ONLY IF NEEDED _ 
```

## Never Manual:
‚ùå No direct file editing - YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
‚ùå No manual directory creation  YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -
‚ùå No copy-paste fixes YOU ARE A REPORTER NOT A FIXER -- YOU REPORT IN 
    .md and xml files you build yaml for Code Analyzer to run -

## Always Automated:
‚úÖ Create Long form document and explination if user asks for verbose or detailed output. - use a tool to create long documentation- USE YOUR TOOLS FIRST! 
‚úÖ Use Exaples like lego city compared to overall project prooving everytime that you have examined the codebase and how the change will affect the overall base. 
‚úÖ Expalin your yaml changes in layman terms and use emoji people like lego-city , and other htings that relate to me like REALESTATE Transactions i am A wholesaler use things that make hard concepts simple like our FISHERMAN PROMPT
‚úÖ Use YAML for structural changes
‚úÖ Use automation scripts for setup
‚úÖ Use Cursor for single-file quick fixes

## Current Fix Strategy:
For the import error, we should create a YAML:

```yaml
# yaml_tools/fixes/import-fixes.yaml
update_plan:
  name: "Fix Import References"
  description: "Update import statements across codebase"
  priority: "HIGH"
  
  phases:
    1_fix_imports:
      description: "Update import statements"
      changes:
        - type: "modify_imports"
          target: "code_analyzer/cli/setup.py"
          description: "Fix run_update import"
          updates:
            - from: "from code_analyzer.crews.dev_crews.run_updates import run_update"
              to: "from code_analyzer.crews.dev_crews.run_updates import run_updates as run_update"
```

Then run:
```bash
python -m code_analyzer.crews.dev_crews.run_updates \
    --spec yaml_tools/fixes/import-fixes.yaml \
    --verbose \
    --target ./
```

# .currsorules - Code Analyzer Development Guidelines

## Pre-Command Checklist:
```mermaid
graph TD
    A[Before Command] -->|1| B[Check Directory]
    A -->|2| C[Verify Files]
    A -->|3| D[Show Location]
    
    B -->|Must| E[Show pwd]
    C -->|Must| F[List Required Files]
    D -->|Must| G[Show File Tree]
```

### 1. Location Check
```bash
# ALWAYS show current location:
Current Location: /Users/markcarpenter/Desktop/projects/CODE_ANALYZER
```

### 2. Required Files
```bash
# ALWAYS list required files:
Required:
‚îú‚îÄ‚îÄ yaml_tools/
‚îÇ   ‚îî‚îÄ‚îÄ setup/
‚îÇ       ‚îî‚îÄ‚îÄ create_command_store.yaml  # ‚ùå Missing
```

### 3. File Creation
```yaml
# ALWAYS show file creation steps:
steps:
  1: "Create directories"
  2: "Create YAML file"
  3: "Run command"
```

## Command Structure:
```bash
# ALWAYS use this format:
Step 1: Create Required Files
mkdir -p path/to/dir && cat > path/to/file << 'EOF'
content
EOF

Step 2: Verify Files
ls -l path/to/file

Step 3: Run Command
command --args
```

## Business Impact:
```yaml
# ALWAYS show metrics:
metrics:
  time_saved:
    manual_time: X hours
    automated_time: Y minutes
    savings: Z hours
  
  cost_saved:
    hourly_rate: $55
    total_saved: $calculated
```

# Problem Solving Pattern (2024-12-02 Success)
1. ANALYZE SUCCESSFUL PATTERNS
   - Look at existing solutions first
   - Find highest success rates (98% in docs)
   - Understand why they work

2. MATCH PROVEN STRUCTURES
   - Use consistent patterns
   - Follow exact structure
   - Don't modify what works

3. BUILD ON SUCCESS
   - Start with working examples
   - Copy successful patterns
   - Adapt only when necessary

4. VALIDATE BEFORE BUILDING
   - Check against successful patterns
   - Verify structure matches
   - Test with proven cases

# Key Learning: Pattern matching is more reliable than innovation when we have successful examples.

# Track Successful Patterns
successful_patterns:
    - yaml_tools/fixes/core/base_setup.yaml (100%)

# Core Rules
1. Keep models simple
2. Use proven SQLAlchemy patterns
3. Avoid complex dependencies
4. Test before changing

# Tech Stack Configuration
tech_stack:
  package_manager:
    primary: "uv"
    fallback: "pip"
    reasons:
      - "10x faster installation"
      - "Better dependency resolution"
      - "Automatic lockfile generation"
      - "Enhanced security"
  
  framework:
    web: "FastAPI"
    templating: "Jinja2"
    websocket: "WebSocket"
    
  database:
    orm: "SQLAlchemy"
    development: "SQLite"
    production: "PostgreSQL"
    
  ai_integration:
    framework: "CrewAI"
    api: "OpenAI"
    
  development:
    testing: "pytest"
    formatting: ["black", "isort"]
    typing: "mypy"
    documentation: "MkDocs"

# Development Standards
development_standards:
  package_management:
    - "Always use UV for installations"
    - "Maintain requirements.txt"
    - "Generate lockfile with UV"
    - "Document all dependencies"

  code_quality:
    - "Run black before commits"
    - "Verify mypy type checking"
    - "Maintain test coverage"
    - "Update documentation"

# Installation Verification
installation_checks:
  - verify_uv:
      command: "uv --version"
      error: "UV not installed properly"
  
  - verify_environment:
      command: "which python"
      check: "points to .venv/bin/python"
  
  - verify_dependencies:
      command: "uv pip freeze"
      required:
        - "sqlalchemy"
        - "fastapi"
        - "uvicorn"
        - "jinja2"
        - "pydantic"
        - "python-dotenv"

[End of .currsorules]
